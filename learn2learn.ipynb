{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn2learn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12DU5kiSBryjbAt4F5J3Ux7ndPQzTCcE_",
      "authorship_tag": "ABX9TyMHKAc9lYU8dZWkTxMbgZ0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pengwork/ANIML/blob/master/learn2learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8aJgXj3-3J4",
        "colab_type": "code",
        "outputId": "c2a309d3-c769-44e1-db0e-d932cae8e6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "!pip install learn2learn"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: learn2learn in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.0.3)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.6.0+cu101)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from learn2learn) (2.21.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.5.0+cu101)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2018.9)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->learn2learn) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xm5tcCrG8Jz",
        "colab_type": "code",
        "outputId": "8885e893-6c5a-49b3-d9c2-e85a1f929049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import learn2learn as l2l\n",
        "import torchvision\n",
        "\n",
        "mnist = torchvision.datasets.MNIST(root=\"/tmp/mnist\", train=True)\n",
        "\n",
        "mnist = l2l.data.MetaDataset(mnist)\n",
        "train_tasks = l2l.data.TaskDataset(mnist,\n",
        "                                   task_transforms=[\n",
        "                                        NWays(mnist, n=3),\n",
        "                                        KShots(mnist, k=1),\n",
        "                                        LoadData(mnist),\n",
        "                                   ],\n",
        "                                   num_tasks=10)\n",
        "model = Net()\n",
        "maml = l2l.algorithms.MAML(model, lr=1e-3, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), lr=4e-3)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    learner = maml.clone()  # Creates a clone of model\n",
        "    for task in train_tasks:\n",
        "        # Split task in adaptation_task and evalutation_task\n",
        "        # Fast adapt\n",
        "        for step in range(adaptation_steps):\n",
        "            error = compute_loss(adaptation_task)\n",
        "            learner.adapt(error)\n",
        "\n",
        "        # Compute evaluation loss\n",
        "        evaluation_error = compute_loss(evaluation_task)\n",
        "\n",
        "        # Meta-update the model parameters\n",
        "        opt.zero_grad()\n",
        "        evaluation_error.backward()\n",
        "        opt.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-fe33cde929eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m train_tasks = l2l.data.TaskDataset(mnist,\n\u001b[1;32m      8\u001b[0m                                    task_transforms=[\n\u001b[0;32m----> 9\u001b[0;31m                                         \u001b[0mNWays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                                         \u001b[0mKShots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                         \u001b[0mLoadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NWays' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHFZ6oHFGt7",
        "colab_type": "code",
        "outputId": "4b1e9f97-4634-4194-abdb-e9e27b38cbd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install fairseq.data.token_block_utils_fast"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement fairseq.data.token_block_utils_fast (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for fairseq.data.token_block_utils_fast\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKuQqv_ujcWo",
        "colab_type": "code",
        "outputId": "57a4f06c-994d-41f0-b21a-e4248ea393bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "import fairseq\n",
        "import fairseq.data.token_block_utils_fast"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ff48c5b1b1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_block_utils_fast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fairseq.data.token_block_utils_fast'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBgsl5cGFF5R",
        "colab_type": "code",
        "outputId": "94f82572-e49a-4bd6-d606-1be670055d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "import argparse\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "import learn2learn as l2l\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, input_dim=768, inner_dim=200, pooler_dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(input_dim, inner_dim)\n",
        "        self.activation_fn = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=pooler_dropout)\n",
        "        self.out_proj = nn.Linear(inner_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense(x)\n",
        "        x = self.activation_fn(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.log_softmax(self.out_proj(x), dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1)\n",
        "    acc = (predictions == targets).sum().float()\n",
        "    acc /= len(targets)\n",
        "    return acc.item()\n",
        "\n",
        "\n",
        "def collate_tokens(values, pad_idx, eos_idx=None, left_pad=False, move_eos_to_beginning=False):\n",
        "    \"\"\"Convert a list of 1d tensors into a padded 2d tensor.\"\"\"\n",
        "    size = max(v.size(0) for v in values)\n",
        "    res = values[0].new(len(values), size).fill_(pad_idx)\n",
        "\n",
        "    def copy_tensor(src, dst):\n",
        "        assert dst.numel() == src.numel()\n",
        "        if move_eos_to_beginning:\n",
        "            assert src[-1] == eos_idx\n",
        "            dst[0] = eos_idx\n",
        "            dst[1:] = src[:-1]\n",
        "        else:\n",
        "            dst.copy_(src)\n",
        "\n",
        "    for i, v in enumerate(values):\n",
        "        copy_tensor(v, res[i][size - len(v):] if left_pad else res[i][:len(v)])\n",
        "    return res\n",
        "\n",
        "\n",
        "def compute_loss(task, roberta, device, learner, loss_func, batch=15):\n",
        "    loss = 0.0\n",
        "    acc = 0.0\n",
        "    for i, (x, y) in enumerate(torch.utils.data.DataLoader(\n",
        "            task, batch_size=batch, shuffle=True, num_workers=0)):\n",
        "        # RoBERTa ENCODING\n",
        "        x = collate_tokens([roberta.encode(sent) for sent in x], pad_idx=1)\n",
        "        with torch.no_grad():\n",
        "            x = roberta.extract_features(x)\n",
        "        x = x[:, 0, :]\n",
        "\n",
        "        # Moving to device\n",
        "        x, y = x.to(device), y.view(-1).to(device)\n",
        "\n",
        "        output = learner(x)\n",
        "        curr_loss = loss_func(output, y)\n",
        "        acc += accuracy(output, y)\n",
        "        loss += curr_loss / len(task)\n",
        "    loss /= len(task)\n",
        "    return loss, acc\n",
        "\n",
        "\n",
        "def main(lr=0.005, maml_lr=0.01, iterations=1000, ways=5, shots=1, tps=32, fas=5, device=torch.device(\"cpu\"),\n",
        "         download_location=\"/tmp/text\"):\n",
        "    text_train = l2l.text.datasets.NewsClassification(root=download_location)\n",
        "    train_gen = l2l.data.TaskDataset(text_train)\n",
        "\n",
        "    torch.hub.set_dir(download_location)\n",
        "    roberta = torch.hub.load('pytorch/fairseq', 'roberta.base')\n",
        "    roberta.eval()\n",
        "    roberta.to(device)\n",
        "    model = Net(num_classes=ways)\n",
        "    model.to(device)\n",
        "    meta_model = l2l.algorithms.MAML(model, lr=maml_lr)\n",
        "    opt = optim.Adam(meta_model.parameters(), lr=lr)\n",
        "    loss_func = nn.NLLLoss(reduction=\"sum\")\n",
        "\n",
        "    tqdm_bar = tqdm(range(iterations))\n",
        "    for iteration in tqdm_bar:\n",
        "        iteration_error = 0.0\n",
        "        iteration_acc = 0.0\n",
        "        for _ in range(tps):\n",
        "            learner = meta_model.clone()\n",
        "            train_task = train_gen.sample(shots=shots)\n",
        "            valid_task = train_gen.sample(shots=shots, classes_to_sample=train_task.sampled_classes)\n",
        "\n",
        "            # Fast Adaptation\n",
        "            for step in range(fas):\n",
        "                train_error, _ = compute_loss(train_task, roberta, device, learner, loss_func, batch=shots * ways)\n",
        "                learner.adapt(train_error)\n",
        "\n",
        "            # Compute validation loss\n",
        "            valid_error, valid_acc = compute_loss(valid_task, roberta, device, learner, loss_func,\n",
        "                                                  batch=shots * ways)\n",
        "            iteration_error += valid_error\n",
        "            iteration_acc += valid_acc\n",
        "\n",
        "        iteration_error /= tps\n",
        "        iteration_acc /= tps\n",
        "        tqdm_bar.set_description(\"Loss : {:.3f} Acc : {:.3f}\".format(iteration_error.item(), iteration_acc))\n",
        "\n",
        "        # Take the meta-learning step\n",
        "        opt.zero_grad()\n",
        "        iteration_error.backward()\n",
        "        opt.step()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  no_cuda = False\n",
        "  use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "\n",
        "  torch.manual_seed(1)\n",
        "  random.seed(1)\n",
        "\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "  main(lr=0.005, maml_lr=0.01, iterations=1000, ways=5, shots=1, tps=32, fas=5, device=device,download_location='temp/text')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # parser = argparse.ArgumentParser(description='Learn2Learn Text Classification Example')\n",
        "\n",
        "    # parser.add_argument('--ways', type=int, default=5, metavar='N',\n",
        "    #                     help='number of ways (default: 5)')\n",
        "    # parser.add_argument('--shots', type=int, default=1, metavar='N',\n",
        "    #                     help='number of shots (default: 1)')\n",
        "    # parser.add_argument('-tps', '--tasks-per-step', type=int, default=32, metavar='N',\n",
        "    #                     help='tasks per step (default: 32)')\n",
        "    # parser.add_argument('-fas', '--fast-adaption-steps', type=int, default=5, metavar='N',\n",
        "    #                     help='steps per fast adaption (default: 5)')\n",
        "\n",
        "    # parser.add_argument('--iterations', type=int, default=1000, metavar='N',\n",
        "    #                     help='number of iterations (default: 1000)')\n",
        "\n",
        "    # parser.add_argument('--lr', type=float, default=0.005, metavar='LR',\n",
        "    #                     help='learning rate (default: 0.005)')\n",
        "    # parser.add_argument('--maml-lr', type=float, default=0.01, metavar='LR',\n",
        "    #                     help='learning rate for MAML (default: 0.01)')\n",
        "\n",
        "    # parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "    #                     help='disables CUDA training')\n",
        "\n",
        "    # parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "    #                     help='random seed (default: 1)')\n",
        "\n",
        "    # parser.add_argument('--download-location', type=str, default=\"/tmp/text\", metavar='S',\n",
        "    #                     help='download location for train data and roberta(default : /tmp/text')\n",
        "\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "    # torch.manual_seed(args.seed)\n",
        "    # random.seed(args.seed)\n",
        "\n",
        "    # device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    # main(lr=args.lr, maml_lr=args.maml_lr, iterations=args.iterations, ways=args.ways, shots=args.shots,\n",
        "    #      tps=args.tasks_per_step, fas=args.fast_adaption_steps, device=device,\n",
        "    #      download_location=args.download_location)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in temp/text/pytorch_fairseq_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/content/temp/text/pytorch_fairseq_master/hubconf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_block_utils_fast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fairseq.data.token_block_utils_fast'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36msave_modules\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mExceptionSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0msaved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36msetup_context\u001b[0;34m(setup_dir)\u001b[0m\n\u001b[1;32m    194\u001b[0m                             \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setuptools'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36mrun_setup\u001b[0;34m(setup_script, args)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdunder_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0m_execfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup_script\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36m_execfile\u001b[0;34m(filename, globals, locals)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, *args, **kw)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_violation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp/text/pytorch_fairseq_master/setup.py'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e5e75a45cbc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaml_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mways\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp/text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-e5e75a45cbc3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(lr, maml_lr, iterations, ways, shots, tps, fas, device, download_location)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mroberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/fairseq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roberta.base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(github, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mhub_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/content/temp/text/pytorch_fairseq_master/hubconf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         sandbox.run_setup(\n\u001b[1;32m     31\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'setup.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0;34m'build_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--inplace'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         )\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36mrun_setup\u001b[0;34m(setup_script, args)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0;31m# Normal exit, just return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36msetup_context\u001b[0;34m(setup_dir)\u001b[0m\n\u001b[1;32m    193\u001b[0m                             \u001b[0;31m# ensure setuptools commands are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                             \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setuptools'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36msave_modules\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m_clear_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdel_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0msaved_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36mresume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/_vendor/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36msave_modules\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0msaved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mExceptionSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0msaved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36msetup_context\u001b[0;34m(setup_dir)\u001b[0m\n\u001b[1;32m    193\u001b[0m                             \u001b[0;31m# ensure setuptools commands are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                             \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setuptools'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36mrun_setup\u001b[0;34m(setup_script, args)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mDirectorySandbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdunder_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0m_execfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup_script\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36m_execfile\u001b[0;34m(filename, globals, locals)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[1;32m     39\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocals\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/setuptools/sandbox.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, *args, **kw)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_violation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtmpnam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp/text/pytorch_fairseq_master/setup.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M7tfUOjGR-e",
        "colab_type": "code",
        "outputId": "9e0aa233-3954-46b0-855a-cc0a206a4924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mpytorch\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtemp\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-R2iAzNGvOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzw4O8VCeD-e",
        "colab_type": "code",
        "outputId": "a8b3465d-c427-4b6e-a9be-daec9be43961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir(\"/content/temp/text/pytorch_fairseq_master\")\n",
        "print(os.getcwd())\n",
        "# path = \"/content/gdrive/My Drive/sample\"\n",
        "# os.chdir(path)\n",
        "# 返回上一级目录\n",
        "# os.chdir('../')\n",
        "# print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/temp/text/pytorch_fairseq_master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6gv6JqtfV0l",
        "colab_type": "code",
        "outputId": "4493e5c1-a999-4136-9aeb-4c3f68c51fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir(\"/content\")\n",
        "print(os.getcwd())\n",
        "# path = \"/content/gdrive/My Drive/sample\"\n",
        "# os.chdir(path)\n",
        "# 返回上一级目录\n",
        "# os.chdir('../')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ezgMQ1vQ9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "2281e42a-aa81-4807-8cd7-2d583c393a09"
      },
      "source": [
        "!python test.py"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<learn2learn.text.datasets.news_classification.NewsClassification object at 0x7f44b5552eb8>\n",
            "<learn2learn.data.meta_dataset.MetaDataset object at 0x7f44b5552ef0>\n",
            "<learn2learn.data.meta_dataset.MetaDataset object at 0x7f44b5552ef0>\n",
            "Using cache found in /tmp/text/pytorch_fairseq_master\n",
            "  0% 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f44ae637048>\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 167, in <module>\n",
            "    download_location=args.download_location)\n",
            "  File \"test.py\", line 108, in main\n",
            "    train_error, _ = compute_loss(train_task, roberta, device, learner, loss_func, batch=shots * ways)\n",
            "  File \"test.py\", line 61, in compute_loss\n",
            "    for i, (x, y) in enumerate(torch.utils.data.DataLoader(task, batch_size=batch, shuffle=True, num_workers=0)):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n",
            "    return torch.stack(batch, 0, out=out)\n",
            "TypeError: expected Tensor as element 1 in argument 0, but got tuple\n",
            "  0% 0/1000 [00:00<?, ?it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iD7n5_WgCsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install fairseq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxL12SSvggp7",
        "colab_type": "code",
        "outputId": "ad24d7de-0603-4ddb-df25-83be97065cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch as th\n",
        "from torch import nn, optim, distributions as dist\n",
        "\n",
        "import learn2learn as l2l\n",
        "\n",
        "DIM = 5\n",
        "TIMESTEPS = 1000\n",
        "TASKS_PER_STEP = 50\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.mu = nn.Parameter(th.randn(DIM))\n",
        "        self.sigma = nn.Parameter(th.randn(DIM))\n",
        "\n",
        "    def forward(self, x=None):\n",
        "        return dist.Normal(self.mu, self.sigma)\n",
        "\n",
        "\n",
        "def main():\n",
        "    task_dist = dist.Normal(th.zeros(2 * DIM), th.ones(2 * DIM))\n",
        "    model = Model()\n",
        "    maml = l2l.algorithms.MAML(model, lr=1e-2)\n",
        "    opt = optim.Adam(maml.parameters())\n",
        "\n",
        "    for i in range(TIMESTEPS):\n",
        "        step_loss = 0.0\n",
        "        for t in range(TASKS_PER_STEP):\n",
        "            # Sample a task\n",
        "            task_params = task_dist.sample()\n",
        "            mu_i, sigma_i = task_params[:DIM], task_params[DIM:]\n",
        "\n",
        "            # Adaptation: Instanciate a copy of model\n",
        "            learner = maml.clone()\n",
        "            proposal = learner()\n",
        "\n",
        "            # Adaptation: Compute and adapt to task loss\n",
        "            loss = (mu_i - proposal.mean).pow(2).sum() + (sigma_i - proposal.variance).pow(2).sum()\n",
        "            learner.adapt(loss)\n",
        "\n",
        "            # Adaptation: Evaluate the effectiveness of adaptation\n",
        "            adapt_loss = (mu_i - proposal.mean).pow(2).sum() + (sigma_i - proposal.variance).pow(2).sum()\n",
        "\n",
        "            # Accumulate the error over all tasks\n",
        "            step_loss += adapt_loss\n",
        "\n",
        "        # Meta-learning step: compute gradient through the adaptation step, automatically.\n",
        "        step_loss = step_loss / TASKS_PER_STEP\n",
        "        print(i, step_loss.item())\n",
        "        opt.zero_grad()\n",
        "        step_loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 17.061962127685547\n",
            "1 19.113014221191406\n",
            "2 17.863384246826172\n",
            "3 18.85416603088379\n",
            "4 17.07343864440918\n",
            "5 18.036943435668945\n",
            "6 15.934466361999512\n",
            "7 16.920808792114258\n",
            "8 19.387113571166992\n",
            "9 19.938034057617188\n",
            "10 18.060535430908203\n",
            "11 17.102968215942383\n",
            "12 17.253414154052734\n",
            "13 19.59915542602539\n",
            "14 19.163097381591797\n",
            "15 17.912517547607422\n",
            "16 17.48438262939453\n",
            "17 16.467491149902344\n",
            "18 17.994991302490234\n",
            "19 18.183429718017578\n",
            "20 16.77085304260254\n",
            "21 16.73499870300293\n",
            "22 17.567752838134766\n",
            "23 17.65776824951172\n",
            "24 17.055801391601562\n",
            "25 17.486984252929688\n",
            "26 19.05139923095703\n",
            "27 17.9143123626709\n",
            "28 17.68560218811035\n",
            "29 18.0966739654541\n",
            "30 17.1558895111084\n",
            "31 18.50570297241211\n",
            "32 17.169475555419922\n",
            "33 18.681337356567383\n",
            "34 18.175025939941406\n",
            "35 18.50633430480957\n",
            "36 17.4508056640625\n",
            "37 17.4473876953125\n",
            "38 16.67022132873535\n",
            "39 17.968456268310547\n",
            "40 18.133161544799805\n",
            "41 17.3918399810791\n",
            "42 16.110803604125977\n",
            "43 17.38953971862793\n",
            "44 17.907304763793945\n",
            "45 17.025665283203125\n",
            "46 16.11427879333496\n",
            "47 16.00165367126465\n",
            "48 19.514047622680664\n",
            "49 17.385719299316406\n",
            "50 17.579999923706055\n",
            "51 18.67339515686035\n",
            "52 17.581584930419922\n",
            "53 17.331661224365234\n",
            "54 17.93024444580078\n",
            "55 17.804380416870117\n",
            "56 18.704856872558594\n",
            "57 16.744403839111328\n",
            "58 17.070512771606445\n",
            "59 16.25889015197754\n",
            "60 17.000125885009766\n",
            "61 17.779064178466797\n",
            "62 19.01636505126953\n",
            "63 18.594409942626953\n",
            "64 17.44257354736328\n",
            "65 17.049070358276367\n",
            "66 17.420318603515625\n",
            "67 16.820711135864258\n",
            "68 16.083553314208984\n",
            "69 17.458742141723633\n",
            "70 16.81622314453125\n",
            "71 17.38649559020996\n",
            "72 16.8604793548584\n",
            "73 16.22785186767578\n",
            "74 18.1763858795166\n",
            "75 17.192665100097656\n",
            "76 17.523181915283203\n",
            "77 16.791902542114258\n",
            "78 17.576047897338867\n",
            "79 15.36640739440918\n",
            "80 16.68055534362793\n",
            "81 16.644798278808594\n",
            "82 19.502967834472656\n",
            "83 18.466611862182617\n",
            "84 16.654991149902344\n",
            "85 19.607481002807617\n",
            "86 14.607686996459961\n",
            "87 19.223386764526367\n",
            "88 18.097332000732422\n",
            "89 17.599136352539062\n",
            "90 15.203612327575684\n",
            "91 15.663322448730469\n",
            "92 16.62009620666504\n",
            "93 16.351844787597656\n",
            "94 16.106477737426758\n",
            "95 15.006270408630371\n",
            "96 16.029754638671875\n",
            "97 17.12697410583496\n",
            "98 16.69236183166504\n",
            "99 15.753758430480957\n",
            "100 17.786054611206055\n",
            "101 15.642546653747559\n",
            "102 15.936113357543945\n",
            "103 15.705305099487305\n",
            "104 16.084867477416992\n",
            "105 15.780045509338379\n",
            "106 18.931013107299805\n",
            "107 16.164339065551758\n",
            "108 14.4219331741333\n",
            "109 17.373241424560547\n",
            "110 15.906307220458984\n",
            "111 14.398724555969238\n",
            "112 17.15399932861328\n",
            "113 18.372840881347656\n",
            "114 17.527711868286133\n",
            "115 15.963143348693848\n",
            "116 15.267219543457031\n",
            "117 15.942826271057129\n",
            "118 17.645301818847656\n",
            "119 17.571359634399414\n",
            "120 14.615534782409668\n",
            "121 14.553075790405273\n",
            "122 16.6260929107666\n",
            "123 16.287660598754883\n",
            "124 16.16667366027832\n",
            "125 16.050342559814453\n",
            "126 16.2705020904541\n",
            "127 16.357572555541992\n",
            "128 16.33277130126953\n",
            "129 16.979476928710938\n",
            "130 15.583751678466797\n",
            "131 16.311935424804688\n",
            "132 16.313730239868164\n",
            "133 16.680072784423828\n",
            "134 16.021926879882812\n",
            "135 16.992115020751953\n",
            "136 14.55984115600586\n",
            "137 16.691024780273438\n",
            "138 15.775494575500488\n",
            "139 15.389229774475098\n",
            "140 15.23725700378418\n",
            "141 18.586894989013672\n",
            "142 15.3100004196167\n",
            "143 14.037449836730957\n",
            "144 16.54330825805664\n",
            "145 14.45981216430664\n",
            "146 15.100651741027832\n",
            "147 16.309114456176758\n",
            "148 13.518331527709961\n",
            "149 16.332088470458984\n",
            "150 15.28833293914795\n",
            "151 16.341617584228516\n",
            "152 15.529170989990234\n",
            "153 16.356098175048828\n",
            "154 16.141029357910156\n",
            "155 15.119980812072754\n",
            "156 16.237184524536133\n",
            "157 16.615022659301758\n",
            "158 15.472753524780273\n",
            "159 14.336132049560547\n",
            "160 16.773950576782227\n",
            "161 16.376976013183594\n",
            "162 18.062318801879883\n",
            "163 17.2990779876709\n",
            "164 14.992191314697266\n",
            "165 15.821810722351074\n",
            "166 16.62116813659668\n",
            "167 15.184721946716309\n",
            "168 15.163601875305176\n",
            "169 14.852383613586426\n",
            "170 15.864391326904297\n",
            "171 18.084697723388672\n",
            "172 13.550253868103027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-f5cb2b40d955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-f5cb2b40d955>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Adaptation: Compute and adapt to task loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmu_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Adaptation: Evaluate the effectiveness of adaptation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/learn2learn/algorithms/maml.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, loss, first_order, allow_unused, allow_nograd)\u001b[0m\n\u001b[1;32m    184\u001b[0m                                  \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                                  \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                                  allow_unused=allow_unused)\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    156\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    157\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcC77G0QjjdB",
        "colab_type": "code",
        "outputId": "d6886027-15c1-4b2c-9b9d-1042f8f3acc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: ERROR: Please provide a package name or names.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ByVFDKctaTm",
        "colab_type": "code",
        "outputId": "d1e6884c-2a19-4dd1-eb75-813c3d9e4738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!where pip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: where: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyY0ytqqtnRK",
        "colab_type": "code",
        "outputId": "87bfb422-2e87-4d01-a911-49c7292432c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!where python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: where: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5admhgtqcQ",
        "colab_type": "code",
        "outputId": "a4dc6554-41d6-4e90-d50e-4bfea9d726d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!which pip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/pip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqJrSCN_ttqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}